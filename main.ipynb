{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ConsistencyAI - Complete Pipeline\n",
        "\n",
        "**A benchmark for evaluating LLM consistency across demographics**\n",
        "\n",
        "By: Peter Banyas, Shristi Sharma, Alistair Simmons, Atharva Vispute (The Duke Phishermen)\n",
        "\n",
        "---\n",
        "\n",
        "## What This Notebook Does\n",
        "\n",
        "This notebook demonstrates the complete ConsistencyAI workflow:\n",
        "\n",
        "1. **Load Personas** - Fetch diverse personas from NVIDIA Nemotron dataset\n",
        "2. **Generate Queries** - Create personalized queries for each persona\n",
        "3. **Query LLMs** - Get responses from multiple language models\n",
        "4. **Compute Similarity** - Analyze response consistency using embeddings\n",
        "5. **Visualize Results** - Create heatmaps, leaderboards, and 3D plots\n",
        "6. **Advanced Analysis** - Clustering and negative similarity detection\n",
        "\n",
        "---\n",
        "\n",
        "## Quick Start\n",
        "\n",
        "**For a fresh run:** Execute each cell in order\n",
        "\n",
        "**To resume from cache:** Use the \"Load from cache\" cells instead of running fresh\n",
        "\n",
        "**To customize:** Edit the configuration in the setup cells\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup & Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dependencies checked/installed\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies (if needed)\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-r', 'requirements.txt'], check=False)\n",
        "    print(\"Dependencies checked/installed\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not install dependencies: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports successful\n",
            "ConsistencyAI ready to use\n",
            "Jupyter compatibility enabled\n"
          ]
        }
      ],
      "source": [
        "# Import the ConsistencyAI package\n",
        "from duplicity import (\n",
        "    # Personas\n",
        "    get_and_clean_personas,\n",
        "    generate_queries_for_personas,\n",
        "    load_latest_personas,\n",
        "    \n",
        "    # Queries\n",
        "    query_llm_fast,\n",
        "    query_llm_fast_resume,\n",
        "    load_latest_results,\n",
        "    load_latest_fast_results,\n",
        "    \n",
        "    # Similarity\n",
        "    supercompute_similarities,\n",
        "    collect_avg_scores_by_model,\n",
        "    save_similarity_results,\n",
        "    load_latest_similarity_results,\n",
        "    load_similarity_results,\n",
        "    \n",
        "    # Visualization\n",
        "    plot_similarity_matrix_with_values,\n",
        "    plot_overall_leaderboard,\n",
        "    plot_similarity_by_sphere,\n",
        "    Embedding3DVisualizer,\n",
        "    \n",
        "    # Advanced Analysis\n",
        "    analyze_and_cluster_embeddings,\n",
        "    print_analysis_summary,\n",
        "    \n",
        "    # Central Analysis\n",
        "    compute_central_analysis,\n",
        "    print_central_analysis_summary,\n",
        "    \n",
        "    # Configuration\n",
        "    config\n",
        ")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Enable nested event loops for Jupyter compatibility\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "print(\"All imports successful\")\n",
        "print(\"ConsistencyAI ready to use\")\n",
        "print(\"Jupyter compatibility enabled\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### API Key Configuration\n",
        "\n",
        "**Important:** If you've already imported the duplicity package and then set your API key, you need to restart the kernel for the changes to take effect.\n",
        "\n",
        "To restart: Kernel → Restart & Clear Output, then re-run all cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: OPENROUTER_API_KEY is not set\n",
            "Set it with: config.set_openrouter_key('your-key')\n"
          ]
        }
      ],
      "source": [
        "# Set your API keys here or via environment variables\n",
        "# Uncomment and add your keys:\n",
        "# config.set_openrouter_key(\"your-key-here\")\n",
        "# config.set_openai_key(\"your-key-here\")  # Optional\n",
        "# config.set_google_key(\"your-key-here\")  # Optional\n",
        "\n",
        "# Check if API key is set\n",
        "if config.OPENROUTER_API_KEY:\n",
        "    print(\"OPENROUTER_API_KEY is set\")\n",
        "else:\n",
        "    print(\"Warning: OPENROUTER_API_KEY is not set\")\n",
        "    print(\"Set it with: config.set_openrouter_key('your-key')\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Experiment Configuration\n",
        "\n",
        "**Customize your experiment here!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment Configuration:\n",
            "   Personas: 50\n",
            "   Topics: 3 (Climate Change, Vaccines, Artificial Intelligence)\n",
            "   Models: 3\n",
            "      - x-ai/grok-4-fast\n",
            "      - anthropic/claude-sonnet-4.5\n",
            "      - google/gemini-2.5-flash\n",
            "   Total queries: 450\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# EXPERIMENT CONFIGURATION - CUSTOMIZE HERE!\n",
        "# ============================================================\n",
        "\n",
        "# Number of personas to test\n",
        "NUM_PERSONAS = 50  # Start small for testing, increase for full experiments\n",
        "\n",
        "# Topics to query about\n",
        "TOPICS = [\n",
        "    \"Climate Change\",\n",
        "    \"Vaccines\",\n",
        "    \"Artificial Intelligence\",\n",
        "]\n",
        "\n",
        "# Models to test\n",
        "MODELS = [\n",
        "    \"x-ai/grok-4-fast\",\n",
        "    \"anthropic/claude-sonnet-4.5\",\n",
        "    \"google/gemini-2.5-flash\",\n",
        "]\n",
        "\n",
        "# API routing configuration\n",
        "ALL_OPEN_ROUTER = True  # Route all models through OpenRouter\n",
        "\n",
        "# Performance settings\n",
        "INITIAL_BATCH_SIZE = 30\n",
        "INITIAL_CONCURRENCY = 10\n",
        "MAX_CONCURRENCY = 50\n",
        "ADAPTIVE_MODE = True\n",
        "\n",
        "# Experiment tag\n",
        "EXPERIMENT_TAG = \"demo_run\"\n",
        "\n",
        "# ============================================================\n",
        "\n",
        "print(\"Experiment Configuration:\")\n",
        "print(f\"   Personas: {NUM_PERSONAS}\")\n",
        "print(f\"   Topics: {len(TOPICS)} ({', '.join(TOPICS)})\")\n",
        "print(f\"   Models: {len(MODELS)}\")\n",
        "for model in MODELS:\n",
        "    print(f\"      - {model}\")\n",
        "total_queries_per_model = NUM_PERSONAS * len(TOPICS)\n",
        "print(f\"   Total queries: {total_queries_per_model * len(MODELS)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 1: Load Personas\n",
        "\n",
        "Fetch diverse personas from the NVIDIA Nemotron dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching 50 personas...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 50 personas\n",
            "\n",
            "Sample Persona:\n",
            "   Age: 72, Sex: Male\n",
            "   Persona: A disciplined, sociable visionary, Jonathan balances practicality with curiosity...\n"
          ]
        }
      ],
      "source": [
        "# Fetch fresh personas\n",
        "print(f\"Fetching {NUM_PERSONAS} personas...\")\n",
        "\n",
        "personas = get_and_clean_personas(\n",
        "    offset=0,\n",
        "    length=NUM_PERSONAS,\n",
        "    cache=True,\n",
        "    tag=EXPERIMENT_TAG\n",
        ")\n",
        "\n",
        "num_personas = len(personas.get('rows', []))\n",
        "print(f\"Loaded {num_personas} personas\")\n",
        "\n",
        "# Show sample\n",
        "if personas['rows']:\n",
        "    sample = personas['rows'][0]['row']\n",
        "    print(f\"\\nSample Persona:\")\n",
        "    print(f\"   Age: {sample.get('age')}, Sex: {sample.get('sex')}\")\n",
        "    print(f\"   Persona: {sample.get('persona', '')[:80]}...\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ALT: Load Cached Personas\n",
        "\n",
        "**Skip fetching** and load the most recent cached personas instead.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 50 personas from cache\n"
          ]
        }
      ],
      "source": [
        "# # ALTERNATIVE: Load cached personas instead of fetching\n",
        "# # Uncomment to use cached data:\n",
        "\n",
        "# personas = load_latest_personas()\n",
        "# if personas:\n",
        "#     num_personas = len(personas.get('rows', []))\n",
        "#     print(f\"Loaded {num_personas} personas from cache\")\n",
        "# else:\n",
        "#     print(\"No cached personas found. Please run the cell above to fetch fresh personas.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 2: Generate Queries\n",
        "\n",
        "Create personalized queries for each persona and topic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating queries for 3 topics...\n",
            "Generated 150 queries per model\n",
            "   Total across all models: 450\n"
          ]
        }
      ],
      "source": [
        "print(f\"Generating queries for {len(TOPICS)} topics...\")\n",
        "\n",
        "queries = generate_queries_for_personas(personas, TOPICS)\n",
        "\n",
        "total_queries_per_model = sum(len(topic_queries) for topic_queries in queries.values())\n",
        "print(f\"Generated {total_queries_per_model} queries per model\")\n",
        "print(f\"   Total across all models: {total_queries_per_model * len(MODELS)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 3: Query LLMs\n",
        "\n",
        "Send queries to language models and collect responses.\n",
        "\n",
        "**Features:** Adaptive concurrency, automatic retries, incremental saving, real-time progress\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting LLM queries...\n",
            "   Estimated time: ~0.8 minutes\n",
            "\\nNote: Progress is saved incrementally. You can stop and resume anytime!\\n\n",
            "🎯 Starting FAST robust query processing (100% success mode):\n",
            "   Models: 3\n",
            "   Topics: 3\n",
            "   Personas per topic: 50\n",
            "   Total queries: 450\n",
            "   Initial batch size: 30\n",
            "   Initial concurrency: 10\n",
            "   Max concurrency: 50\n",
            "   Adaptive mode: True\n",
            "   All OpenRouter: True\n",
            "   Max retries: 5\n",
            "   100% success mode: True\n",
            "   Incremental saving: True\n",
            "   Incremental interval: Every 1 batch(es)\n",
            "   Incremental folder: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental\n",
            "📋 Created 450 expected task combinations (model×topic×persona)\n",
            "   Total batches: 15\n",
            "🚀 Processing batch 1/15 (30 queries, concurrency: 10, current batch size: 30)\n",
            "✅ Batch 1 complete: 30 success, 0 failed, 26830 tokens, 30.1s\n",
            "📈 Increasing batch size from 30 to 40 (success rate: 100.0%)\n",
            "📝 Progress saved: 1/15 batches complete (ETA: 0:07:00)\n",
            "📁 Incremental results saved: incremental_results_20251009_000435_batch001_batch_001.json\n",
            "   Progress: 1/15 (6.7%)\n",
            "   File: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental/incremental_results_20251009_000435_batch001_batch_001.json\n",
            "📊 Progress: 30/450 (6.7%)\n",
            "   Speed: 1.0 queries/sec | Success: 100.0%\n",
            "   ETA: 7m | Concurrency: 10 | Batch size: 40\n",
            "⏳ Minimal delay: 0.1s (excellent performance: 100.0%)\n",
            "🚀 Processing batch 2/12 (40 queries, concurrency: 10, current batch size: 40)\n",
            "✅ Batch 2 complete: 40 success, 0 failed, 35864 tokens, 31.8s\n",
            "📈 Increasing batch size from 40 to 50 (success rate: 100.0%)\n",
            "📝 Progress saved: 2/12 batches complete (ETA: 0:05:10)\n",
            "📁 Incremental results saved: incremental_results_20251009_000435_batch002_batch_002.json\n",
            "   Progress: 2/12 (16.7%)\n",
            "   File: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental/incremental_results_20251009_000435_batch002_batch_002.json\n",
            "📊 Progress: 70/450 (15.6%)\n",
            "   Speed: 1.1 queries/sec | Success: 100.0%\n",
            "   ETA: 5m | Concurrency: 10 | Batch size: 50\n",
            "⏳ Minimal delay: 0.1s (excellent performance: 100.0%)\n",
            "🚀 Processing batch 3/10 (50 queries, concurrency: 10, current batch size: 50)\n",
            "✅ Batch 3 complete: 50 success, 0 failed, 44971 tokens, 42.6s\n",
            "📈 Increasing batch size from 50 to 60 (success rate: 100.0%)\n",
            "📝 Progress saved: 3/10 batches complete (ETA: 0:04:04)\n",
            "📁 Incremental results saved: incremental_results_20251009_000435_batch003_batch_003.json\n",
            "   Progress: 3/10 (30.0%)\n",
            "   File: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental/incremental_results_20251009_000435_batch003_batch_003.json\n",
            "📊 Progress: 120/450 (26.7%)\n",
            "   Speed: 1.1 queries/sec | Success: 100.0%\n",
            "   ETA: 4m | Concurrency: 10 | Batch size: 60\n",
            "⏳ Minimal delay: 0.1s (excellent performance: 100.0%)\n",
            "🚀 Processing batch 4/9 (60 queries, concurrency: 10, current batch size: 60)\n",
            "✅ Batch 4 complete: 60 success, 0 failed, 53281 tokens, 50.9s\n",
            "📈 Increasing batch size from 60 to 70 (success rate: 100.0%)\n",
            "🚀 High success rate (100.0%) - increasing concurrency to 12\n",
            "📝 Progress saved: 4/9 batches complete (ETA: 0:03:14)\n",
            "📁 Incremental results saved: incremental_results_20251009_000435_batch004_batch_004.json\n",
            "   Progress: 4/9 (44.4%)\n",
            "   File: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental/incremental_results_20251009_000435_batch004_batch_004.json\n",
            "📊 Progress: 180/450 (40.0%)\n",
            "   Speed: 1.2 queries/sec | Success: 100.0%\n",
            "   ETA: 3m | Concurrency: 12 | Batch size: 70\n",
            "⏳ Minimal delay: 0.1s (excellent performance: 100.0%)\n",
            "🚀 Processing batch 5/8 (70 queries, concurrency: 12, current batch size: 70)\n",
            "✅ Batch 5 complete: 70 success, 0 failed, 61549 tokens, 53.0s\n",
            "📈 Increasing batch size from 70 to 80 (success rate: 100.0%)\n",
            "📝 Progress saved: 5/8 batches complete (ETA: 0:02:05)\n",
            "📁 Incremental results saved: incremental_results_20251009_000435_batch005_batch_005.json\n",
            "   Progress: 5/8 (62.5%)\n",
            "   File: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental/incremental_results_20251009_000435_batch005_batch_005.json\n",
            "📊 Progress: 250/450 (55.6%)\n",
            "   Speed: 1.2 queries/sec | Success: 100.0%\n",
            "   ETA: 2m | Concurrency: 12 | Batch size: 80\n",
            "⏳ Minimal delay: 0.1s (excellent performance: 100.0%)\n",
            "🚀 Processing batch 6/8 (80 queries, concurrency: 12, current batch size: 80)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 2.0s... (attempt 2/3)\n",
            "❌ Max retries reached, returning invalid response\n",
            "🔄 Added to retry queue: anthropic/claude-sonnet-4.5_Artificial Intelligence_2 (attempt 1/5)\n",
            "✅ Batch 6 complete: 79 success, 1 failed, 68782 tokens, 72.8s\n",
            "📈 Increasing batch size from 80 to 90 (success rate: 98.8%)\n",
            "📝 Progress saved: 6/8 batches complete (ETA: 0:01:33)\n",
            "🔄 Retry queue: 1 items pending\n",
            "📁 Incremental results saved: incremental_results_20251009_000435_batch006_batch_006.json\n",
            "   Progress: 6/8 (75.0%)\n",
            "   File: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental/incremental_results_20251009_000435_batch006_batch_006.json\n",
            "📊 Progress: 330/450 (73.3%)\n",
            "   Speed: 1.2 queries/sec | Success: 99.7%\n",
            "   ETA: 1m | Concurrency: 12 | Batch size: 90\n",
            "⏳ Minimal delay: 0.1s (excellent performance: 99.7%)\n",
            "🚀 Processing batch 7/8 (90 queries, concurrency: 12, current batch size: 90)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 2.0s... (attempt 2/3)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 2.0s... (attempt 2/3)\n",
            "⚠️  Empty/invalid response, retrying in 2.0s... (attempt 2/3)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 2.0s... (attempt 2/3)\n",
            "❌ Max retries reached, returning invalid response\n",
            "🔄 Added to retry queue: anthropic/claude-sonnet-4.5_Artificial Intelligence_38 (attempt 1/5)\n",
            "✅ Batch 7 complete: 89 success, 1 failed, 76388 tokens, 100.5s\n",
            "📈 Increasing batch size from 90 to 100 (success rate: 98.9%)\n",
            "📝 Progress saved: 7/8 batches complete (ETA: 0:00:54)\n",
            "🔄 Retry queue: 2 items pending\n",
            "📁 Incremental results saved: incremental_results_20251009_000435_batch007_batch_007.json\n",
            "   Progress: 7/8 (87.5%)\n",
            "   File: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental/incremental_results_20251009_000435_batch007_batch_007.json\n",
            "📊 Progress: 420/450 (93.3%)\n",
            "   Speed: 1.1 queries/sec | Success: 99.5%\n",
            "   ETA: 0m | Concurrency: 12 | Batch size: 100\n",
            "⏳ Minimal delay: 0.1s (excellent performance: 99.5%)\n",
            "🚀 Processing batch 8/8 (30 queries, concurrency: 12, current batch size: 100)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 2.0s... (attempt 2/3)\n",
            "❌ Max retries reached, returning invalid response\n",
            "🔄 Added to retry queue: anthropic/claude-sonnet-4.5_Artificial Intelligence_43 (attempt 1/5)\n",
            "✅ Batch 8 complete: 29 success, 1 failed, 24805 tokens, 45.3s\n",
            "🚀 High success rate (96.7%) - increasing concurrency to 14\n",
            "📝 Progress saved: 8/8 batches complete (ETA: 0:00:00)\n",
            "🔄 Retry queue: 3 items pending\n",
            "📁 Incremental results saved: incremental_results_20251009_000435_batch008_batch_008.json\n",
            "   Progress: 8/8 (100.0%)\n",
            "   File: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental/incremental_results_20251009_000435_batch008_batch_008.json\n",
            "📊 Progress: 450/450 (100.0%)\n",
            "   Speed: 1.1 queries/sec | Success: 99.3%\n",
            "   ETA: 0m | Concurrency: 14 | Batch size: 100\n",
            "\n",
            "🔄 Processing retry queue to achieve 100% success...\n",
            "\n",
            "🔄 Retry round 1/5\n",
            "🔄 Processing 3 failed items with SMART retry logic...\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "⚠️  Empty/invalid response, retrying in 2.0s... (attempt 2/3)\n",
            "❌ Max retries reached, returning invalid response\n",
            "✅ Retry round complete: 2 successful, 1 still failed\n",
            "   Retry success rate: 66.7%\n",
            "📁 Incremental results saved: incremental_results_20251009_000435_batch015_retry_round_1_009.json\n",
            "   Progress: 15/15 (100.0%)\n",
            "   File: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental/incremental_results_20251009_000435_batch015_retry_round_1_009.json\n",
            "⏳ Waiting 2.0s before next retry round...\n",
            "\n",
            "🔄 Retry round 2/5\n",
            "🔄 Processing 1 failed items with SMART retry logic...\n",
            "⚠️  Empty/invalid response, retrying in 1.0s... (attempt 1/3)\n",
            "✅ Retry round complete: 1 successful, 0 still failed\n",
            "   Retry success rate: 100.0%\n",
            "🚀 High retry success rate - can be more aggressive in future\n",
            "📁 Incremental results saved: incremental_results_20251009_000435_batch015_retry_round_2_010.json\n",
            "   Progress: 15/15 (100.0%)\n",
            "   File: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental/incremental_results_20251009_000435_batch015_retry_round_2_010.json\n",
            "🎉 All retries successful! 100% success achieved!\n",
            "\n",
            "🔍 Checking for missing task combinations...\n",
            "✅ All expected task combinations are present!\n",
            "📁 Incremental results saved: incremental_results_20251009_000435_batch015_final_011.json\n",
            "   Progress: 15/15 (100.0%)\n",
            "   File: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental/incremental_results_20251009_000435_batch015_final_011.json\n",
            "\n",
            "📊 Final Results:\n",
            "   Total queries processed: 453\n",
            "   Successful: 450 (99.3%)\n",
            "   Failed: 3 (0.7%)\n",
            "   \n",
            "   📋 Coverage Report:\n",
            "      Expected task combinations: 450\n",
            "      Completed task combinations: 450\n",
            "      Coverage: 100.0%\n",
            "   \n",
            "   Total tokens used: 395052\n",
            "   Total time: 503.3s (8.4 minutes)\n",
            "   Average speed: 0.9 queries/sec\n",
            "   Final concurrency: 14\n",
            "   Retry attempts: 3\n",
            "   Max retries reached: 0\n",
            "   Incremental files saved: 11 files in /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/incremental\n",
            "🎉 PERFECT: 100% coverage with 99%+ success rate!\n",
            "\\nAll queries complete!\n",
            "   x-ai/grok-4-fast: 150 responses\n",
            "   anthropic/claude-sonnet-4.5: 150 responses\n",
            "   google/gemini-2.5-flash: 150 responses\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting LLM queries...\")\n",
        "print(f\"   Estimated time: ~{(total_queries_per_model * len(MODELS)) / 10 / 60:.1f} minutes\")\n",
        "print(\"\\\\nNote: Progress is saved incrementally. You can stop and resume anytime!\\\\n\")\n",
        "\n",
        "results = query_llm_fast(\n",
        "    nested_queries=queries,\n",
        "    list_of_models=MODELS,\n",
        "    initial_batch_size=INITIAL_BATCH_SIZE,\n",
        "    initial_concurrency=INITIAL_CONCURRENCY,\n",
        "    max_concurrency=MAX_CONCURRENCY,\n",
        "    adaptive_mode=ADAPTIVE_MODE,\n",
        "    all_open_router=ALL_OPEN_ROUTER,\n",
        "    ensure_100_percent_success=True,\n",
        "    save_incremental=True,\n",
        "    max_retries=5\n",
        ")\n",
        "\n",
        "print(\"\\\\nAll queries complete!\")\n",
        "for model in results:\n",
        "    total_responses = sum(len(personas) for personas in results[model].values())\n",
        "    print(f\"   {model}: {total_responses} responses\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ALT: Load Cached Results\n",
        "\n",
        "**Skip querying** and load the most recent LLM results instead. This saves time and API costs!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded query results from cache!\n",
            "   x-ai/grok-4-fast: 150 responses\n",
            "   anthropic/claude-sonnet-4.5: 150 responses\n",
            "   google/gemini-2.5-flash: 150 responses\n"
          ]
        }
      ],
      "source": [
        "# # ALTERNATIVE: Load cached query results instead of running fresh queries\n",
        "# # Uncomment to use cached data:\n",
        "\n",
        "# results = load_latest_fast_results()\n",
        "# if results:\n",
        "#     print(\"Loaded query results from cache!\")\n",
        "#     for model in results:\n",
        "#         total_responses = sum(len(personas) for personas in results[model].values())\n",
        "#         print(f\"   {model}: {total_responses} responses\")\n",
        "# else:\n",
        "#     print(\"No cached results found. Please run Step 3 above to query LLMs.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 4: Compute Similarity\n",
        "\n",
        "Analyze response consistency using semantic embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing semantic similarity matrices...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing similarities:   0%|          | 0/9 [00:00<?, ?topic/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading sentence-transformers model from cache...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing similarities: 100%|██████████| 9/9 [00:07<00:00,  1.27topic/s, current=google/gemini-2.5-flash/Artificial Intelligence]    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nSimilarity computation complete!\n",
            "   Matrices computed: 9\n",
            "   Saved to: /Users/peterbanyas/Desktop/Cyber/openai/duplicity3/consistencyAI/logs/similarities_20251009_004201_demo_run.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Computing semantic similarity matrices...\")\n",
        "\n",
        "matrices, dfs, persona_ids, embeddings = supercompute_similarities(results)\n",
        "\n",
        "print(f\"\\\\nSimilarity computation complete!\")\n",
        "print(f\"   Matrices computed: {sum(len(topics) for topics in matrices.values())}\")\n",
        "\n",
        "# Save results\n",
        "similarity_path = save_similarity_results(matrices, dfs, persona_ids, embeddings, tag=EXPERIMENT_TAG)\n",
        "print(f\"   Saved to: {similarity_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### ALT: Load Cached Similarity Results\n",
        "\n",
        "**Skip similarity computation** and load the most recent cached similarity matrices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded similarity results from cache!\n",
            "   Matrices computed: 9\n"
          ]
        }
      ],
      "source": [
        "# # ALTERNATIVE: Load cached similarity results instead of computing\n",
        "# # Uncomment to use cached data:\n",
        "\n",
        "# # OPTION 1: Load the latest .PKL file\n",
        "similarity_data = load_latest_similarity_results()\n",
        "\n",
        "# # # OPTION 2: Load a specific .PKL file\n",
        "# similarity_data = load_similarity_results(\"logs/similarities_20251009_004201_demo_run.pkl\")\n",
        "\n",
        "if similarity_data:\n",
        "    matrices, dfs, persona_ids, embeddings = similarity_data\n",
        "    print(\"Loaded similarity results from cache!\")\n",
        "    print(f\"   Matrices computed: {sum(len(topics) for topics in matrices.values())}\")\n",
        "else:\n",
        "    print(\"No cached similarity results found. Please run Step 4 above to compute similarities.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Similarity Scores:\n",
            "   (Higher = more consistent)\\n\n",
            "\\nx-ai/grok-4-fast:\n",
            "   Climate Change: 0.8798\n",
            "   Vaccines: 0.8846\n",
            "   Artificial Intelligence: 0.8531\n",
            "   Overall: 0.8725\n",
            "\\nanthropic/claude-sonnet-4.5:\n",
            "   Climate Change: 0.9380\n",
            "   Vaccines: 0.8262\n",
            "   Artificial Intelligence: 0.7471\n",
            "   Overall: 0.8371\n",
            "\\ngoogle/gemini-2.5-flash:\n",
            "   Climate Change: 0.8692\n",
            "   Vaccines: 0.8630\n",
            "   Artificial Intelligence: 0.8374\n",
            "   Overall: 0.8565\n"
          ]
        }
      ],
      "source": [
        "# Compute average scores\n",
        "avg_scores = collect_avg_scores_by_model(matrices)\n",
        "\n",
        "print(\"Average Similarity Scores:\")\n",
        "print(\"   (Higher = more consistent)\\\\n\")\n",
        "\n",
        "for model in avg_scores:\n",
        "    print(f\"\\\\n{model}:\")\n",
        "    for topic in avg_scores[model]:\n",
        "        score = avg_scores[model][topic]\n",
        "        print(f\"   {topic}: {score:.4f}\")\n",
        "    overall = np.mean(list(avg_scores[model].values()))\n",
        "    print(f\"   Overall: {overall:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 5: Visualizations\n",
        "\n",
        "Create informative plots to understand model behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating overall leaderboard...\n",
            "Saved overall leaderboard plot to: output/overall_leaderboard.png\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Leaderboard saved to: output/overall_leaderboard.png\n"
          ]
        }
      ],
      "source": [
        "# Create overall leaderboard\n",
        "print(\"Creating overall leaderboard...\")\n",
        "\n",
        "plot_overall_leaderboard(avg_scores, save_path=\"output\", show=True)\n",
        "\n",
        "print(\"Leaderboard saved to: output/overall_leaderboard.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating topic-specific plots...\n",
            "Saved similarity by sphere plot to: output/similarity_by_sphere_Climate_Change.png\n",
            "Saved similarity by sphere plot to: output/similarity_by_sphere_Vaccines.png\n",
            "Saved similarity by sphere plot to: output/similarity_by_sphere_Artificial_Intelligence.png\n",
            "Topic plots saved to: output/\n"
          ]
        }
      ],
      "source": [
        "# Create topic-specific plots\n",
        "print(\"Creating topic-specific plots...\")\n",
        "\n",
        "plot_similarity_by_sphere(avg_scores, save_path=\"output\")\n",
        "\n",
        "print(\"Topic plots saved to: output/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating similarity heatmaps...\n",
            "All heatmaps saved to: output/\n"
          ]
        }
      ],
      "source": [
        "# Create similarity heatmaps for each model/topic\n",
        "print(\"Creating similarity heatmaps...\")\n",
        "\n",
        "for model in matrices:\n",
        "    for topic in matrices[model]:\n",
        "        safe_model = model.replace(\"/\", \"_\")\n",
        "        safe_topic = topic.replace(\" \", \"_\")\n",
        "        save_path = f\"output/heatmap_{safe_model}_{safe_topic}.png\"\n",
        "        \n",
        "        fig, ax = plot_similarity_matrix_with_values(\n",
        "            similarity_matrix=matrices[model][topic],\n",
        "            persona_ids=persona_ids[model][topic],\n",
        "            show_values=(len(persona_ids[model][topic]) <= 20),\n",
        "            model_name=model,\n",
        "            topic=topic,\n",
        "            save_path=save_path\n",
        "        )\n",
        "        plt.close(fig)\n",
        "\n",
        "print(\"All heatmaps saved to: output/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 6: Analysis Part 1\n",
        "\n",
        "Perform clustering and detect negative similarities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing comprehensive analysis...\n",
            "Analyzing x-ai/grok-4-fast - Climate Change...\n",
            "Analyzing x-ai/grok-4-fast - Vaccines...\n",
            "Analyzing x-ai/grok-4-fast - Artificial Intelligence...\n",
            "Analyzing anthropic/claude-sonnet-4.5 - Climate Change...\n",
            "Analyzing anthropic/claude-sonnet-4.5 - Vaccines...\n",
            "Analyzing anthropic/claude-sonnet-4.5 - Artificial Intelligence...\n",
            "Analyzing google/gemini-2.5-flash - Climate Change...\n",
            "Analyzing google/gemini-2.5-flash - Vaccines...\n",
            "Analyzing google/gemini-2.5-flash - Artificial Intelligence...\n",
            "\\nAnalysis complete!\n",
            "\n",
            "================================================================================\n",
            "EMBEDDING ANALYSIS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Model: x-ai/grok-4-fast\n",
            "----------------------------------------\n",
            "  Topic: Climate Change\n",
            "    No negative similarities found\n",
            "    Optimal clusters: 2\n",
            "    Plot saved: output/clustering/clustering_x-ai/grok-4-fast_Climate Change.png\n",
            "  Topic: Vaccines\n",
            "    No negative similarities found\n",
            "    Optimal clusters: 2\n",
            "    Plot saved: output/clustering/clustering_x-ai/grok-4-fast_Vaccines.png\n",
            "  Topic: Artificial Intelligence\n",
            "    No negative similarities found\n",
            "    Optimal clusters: 2\n",
            "    Plot saved: output/clustering/clustering_x-ai/grok-4-fast_Artificial Intelligence.png\n",
            "\n",
            "Model: anthropic/claude-sonnet-4.5\n",
            "----------------------------------------\n",
            "  Topic: Climate Change\n",
            "    No negative similarities found\n",
            "    Optimal clusters: 6\n",
            "    Plot saved: output/clustering/clustering_anthropic/claude-sonnet-4.5_Climate Change.png\n",
            "  Topic: Vaccines\n",
            "    No negative similarities found\n",
            "    Optimal clusters: 2\n",
            "    Plot saved: output/clustering/clustering_anthropic/claude-sonnet-4.5_Vaccines.png\n",
            "  Topic: Artificial Intelligence\n",
            "    No negative similarities found\n",
            "    Optimal clusters: 2\n",
            "    Plot saved: output/clustering/clustering_anthropic/claude-sonnet-4.5_Artificial Intelligence.png\n",
            "\n",
            "Model: google/gemini-2.5-flash\n",
            "----------------------------------------\n",
            "  Topic: Climate Change\n",
            "    No negative similarities found\n",
            "    Optimal clusters: 2\n",
            "    Plot saved: output/clustering/clustering_google/gemini-2.5-flash_Climate Change.png\n",
            "  Topic: Vaccines\n",
            "    No negative similarities found\n",
            "    Optimal clusters: 3\n",
            "    Plot saved: output/clustering/clustering_google/gemini-2.5-flash_Vaccines.png\n",
            "  Topic: Artificial Intelligence\n",
            "    No negative similarities found\n",
            "    Optimal clusters: 2\n",
            "    Plot saved: output/clustering/clustering_google/gemini-2.5-flash_Artificial Intelligence.png\n",
            "\n",
            "================================================================================\n",
            "TOTAL NEGATIVE SIMILARITY PAIRS: 0\n",
            "TOTAL OPTIMAL CLUSTERS: 23\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"Performing comprehensive analysis...\")\n",
        "\n",
        "analysis_results = analyze_and_cluster_embeddings(\n",
        "    all_embeddings=embeddings,\n",
        "    all_similarity_matrices=matrices,\n",
        "    all_sorted_personas=persona_ids,\n",
        "    max_clusters=10,\n",
        "    random_state=42,\n",
        "    save_plots=True,\n",
        "    plots_dir=\"output/clustering\"\n",
        ")\n",
        "\n",
        "print(\"\\\\nAnalysis complete!\")\n",
        "\n",
        "# Print summary\n",
        "print_analysis_summary(analysis_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 7: Central Analysis\n",
        "\n",
        "Compute weighted consistency metrics across models and topics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running central analysis...\n",
            "Central analysis complete!\n",
            "\n",
            "Files saved to: output/analysis/\n",
            "   - per_model_per_topic.csv\n",
            "   - model_overall_weighted.csv\n",
            "   - topic_across_models_weighted.csv\n",
            "   - summary.txt\n",
            "   - README.md\n"
          ]
        }
      ],
      "source": [
        "print(\"Running central analysis...\")\n",
        "\n",
        "# Compute central analysis metrics\n",
        "per_model_per_topic, model_overall_weighted, topic_across_models_weighted, benchmark = \\\n",
        "    compute_central_analysis(matrices, output_dir=\"output/analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "CENTRAL ANALYSIS RESULTS\n",
            "================================================================================\n",
            "\n",
            "Benchmark (mean of models' weighted means): 0.855392\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Top Models by Weighted Mean Similarity:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "                      model  weighted_mean_similarity  topics_count  total_pairs\n",
            "           x-ai/grok-4-fast                  0.872517             3         3675\n",
            "    google/gemini-2.5-flash                  0.856537             3         3675\n",
            "anthropic/claude-sonnet-4.5                  0.837123             3         3675\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Top Topics by Response-Weighted Consistency:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "                  topic  response_weighted_topic_consistency  models_contributing  total_response_pairs\n",
            "         Climate Change                             0.895669                    3                  3675\n",
            "               Vaccines                             0.857949                    3                  3675\n",
            "Artificial Intelligence                             0.812559                    3                  3675\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Display results\n",
        "print_central_analysis_summary(model_overall_weighted, topic_across_models_weighted, benchmark)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Experiment Complete\n",
        "\n",
        "### What you just did:\n",
        "\n",
        "- Loaded diverse personas from NVIDIA Nemotron dataset  \n",
        "- Generated personalized queries for each persona  \n",
        "- Queried multiple LLMs with adaptive concurrency  \n",
        "- Computed semantic similarity across responses  \n",
        "- Created comprehensive visualizations  \n",
        "- Performed clustering analysis  \n",
        "- Generated weighted consistency metrics and benchmark scores\n",
        "\n",
        "### Understanding results:\n",
        "\n",
        "**Similarity Scores:**\n",
        "- **1.0** = Perfect consistency (identical facts)\n",
        "- **0.8-0.99** = High consistency\n",
        "- **0.5-0.8** = Moderate consistency -- some discrepancies and/or differences in focus\n",
        "- **0.0-0.5** = Low consistency -- talking about totally unrelated things\n",
        "- **Negative** = Opposing facts (contradictory information)\n",
        "\n",
        "### Output Files:\n",
        "\n",
        "**Visualizations** (`output/`):\n",
        "- Heatmaps, leaderboards, and topic-specific plots\n",
        "- Clustering analysis plots (`output/clustering/`)\n",
        "\n",
        "**Central Analysis** (`output/analysis/`):\n",
        "- `per_model_per_topic.csv` - detailed similarity metrics\n",
        "- `model_overall_weighted.csv` - model rankings with weighted scores\n",
        "- `topic_across_models_weighted.csv` - topic consistency across models\n",
        "- `summary.txt` - benchmark and top-5 leaderboards\n",
        "- `README.md` - documentation\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. **Explore visualizations and analysis results in `output/` directory**\n",
        "2. Review the benchmark score and model rankings in `output/analysis/`\n",
        "3. Adjust configuration and re-run\n",
        "4. Try more models or topics\n",
        "5. Share your findings!\n",
        "\n",
        "---\n",
        "\n",
        "**Built by the Duke Phishermen**  \n",
        "Peter Banyas, Shristi Sharma, Alistair Simmons, Atharva Vispute\n",
        "\n",
        "With inquiries, questions, & feedback, please contact: peter dot banyas at duke dot edu\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
